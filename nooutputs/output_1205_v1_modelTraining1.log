2023-12-05 21:07:26.412029: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
(198403, 81)
                  time  time_sin  ...  outdoor_solarradiation  outdoor_solarenergy
0  2023-06-27 17:53:00 -0.999534  ...                     0.0                  0.0
1  2023-06-27 17:54:00 -0.999657  ...                     0.0                  0.0
2  2023-06-27 17:55:00 -0.999762  ...                     0.0                  0.0
3  2023-06-27 17:56:00 -0.999848  ...                     0.0                  0.0
4  2023-06-27 17:57:00 -0.999914  ...                     0.0                  0.0

[5 rows x 81 columns]
2023-06-27 17:53:00
2023-10-04 22:35:00
                      time  ...  outdoor_solarenergy
198398 2023-10-31 19:33:00  ...                  0.0
198399 2023-10-31 19:34:00  ...                  0.0
198400 2023-10-31 19:35:00  ...                  0.0
198401 2023-10-31 19:36:00  ...                  0.0
198402 2023-10-31 19:37:00  ...                  0.0

[5 rows x 81 columns]
Index(['time', 'time_sin', 'time_cos', 'Occupancy', 'door_gap', 'window_gap',
       'humidity', 'VOC_ppb', 'temperature_Main', 'temperature_FRT',
       'temperature_FRM', 'temperature_FRB', 'temperature_FMT',
       'temperature_FMM', 'temperature_FMB', 'temperature_FLT',
       'temperature_FLM', 'temperature_FLB', 'temperature_BRT',
       'temperature_BRM', 'temperature_BRB', 'temperature_BMT',
       'temperature_BMM', 'temperature_BMB', 'temperature_BLT',
       'temperature_BLM', 'temperature_BLB', 'temperature_WRB',
       'temperature_WMB', 'temperature_WLB', 'temperature_WLF',
       'temperature_DoorRT', 'temperature_BTable', 'temperature_PRUR',
       'temperature_PRUL', 'temperature_PRDR', 'temperature_PRDL',
       'temperature_PLDR', 'temperature_PLDL', 'temperature_Out', 'light_FRT',
       'light_FRM', 'light_FRB', 'light_FMT', 'light_FMM', 'light_FMB',
       'light_FLT', 'light_FLM', 'light_FLB', 'light_BRT', 'light_BRM',
       'light_BRB', 'light_BMT', 'light_BMM', 'light_BMB', 'light_BLT',
       'light_BLM', 'light_BLB', 'light_WRB', 'light_WMB', 'light_WLB',
       'light_WLF', 'light_DoorRT', 'light_BTable', 'light_PRUR', 'light_PRUL',
       'light_PRDR', 'light_PRDL', 'light_PLDR', 'light_PLDL', 'light_Out',
       'outdoor_temperature', 'outdoor_humidity', 'outdoor_windgust',
       'outdoor_windspeed', 'outdoor_winddir', 'outdoor_sealevelpressure',
       'outdoor_dew', 'outdoor_cloudcover', 'outdoor_solarradiation',
       'outdoor_solarenergy'],
      dtype='object')
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 198403 entries, 0 to 198402
Data columns (total 81 columns):
 #   Column                    Non-Null Count   Dtype         
---  ------                    --------------   -----         
 0   time                      198403 non-null  datetime64[ns]
 1   time_sin                  198403 non-null  float64       
 2   time_cos                  198403 non-null  float64       
 3   Occupancy                 198403 non-null  float64       
 4   door_gap                  198403 non-null  float64       
 5   window_gap                198403 non-null  float64       
 6   humidity                  198403 non-null  float64       
 7   VOC_ppb                   198403 non-null  float64       
 8   temperature_Main          198403 non-null  float64       
 9   temperature_FRT           0 non-null       float64       
 10  temperature_FRM           0 non-null       float64       
 11  temperature_FRB           0 non-null       float64       
 12  temperature_FMT           0 non-null       float64       
 13  temperature_FMM           0 non-null       float64       
 14  temperature_FMB           0 non-null       float64       
 15  temperature_FLT           0 non-null       float64       
 16  temperature_FLM           0 non-null       float64       
 17  temperature_FLB           0 non-null       float64       
 18  temperature_BRT           198403 non-null  float64       
 19  temperature_BRM           198403 non-null  float64       
 20  temperature_BRB           198403 non-null  float64       
 21  temperature_BMT           198403 non-null  float64       
 22  temperature_BMM           198403 non-null  float64       
 23  temperature_BMB           0 non-null       float64       
 24  temperature_BLT           198403 non-null  float64       
 25  temperature_BLM           0 non-null       float64       
 26  temperature_BLB           198403 non-null  float64       
 27  temperature_WRB           198403 non-null  float64       
 28  temperature_WMB           198403 non-null  float64       
 29  temperature_WLB           198403 non-null  float64       
 30  temperature_WLF           198403 non-null  float64       
 31  temperature_DoorRT        198403 non-null  float64       
 32  temperature_BTable        198403 non-null  float64       
 33  temperature_PRUR          198403 non-null  float64       
 34  temperature_PRUL          198403 non-null  float64       
 35  temperature_PRDR          198403 non-null  float64       
 36  temperature_PRDL          198403 non-null  float64       
 37  temperature_PLDR          198403 non-null  float64       
 38  temperature_PLDL          0 non-null       float64       
 39  temperature_Out           198403 non-null  float64       
 40  light_FRT                 0 non-null       float64       
 41  light_FRM                 0 non-null       float64       
 42  light_FRB                 0 non-null       float64       
 43  light_FMT                 0 non-null       float64       
 44  light_FMM                 0 non-null       float64       
 45  light_FMB                 0 non-null       float64       
 46  light_FLT                 0 non-null       float64       
 47  light_FLM                 0 non-null       float64       
 48  light_FLB                 0 non-null       float64       
 49  light_BRT                 198403 non-null  float64       
 50  light_BRM                 198403 non-null  float64       
 51  light_BRB                 198403 non-null  float64       
 52  light_BMT                 198403 non-null  float64       
 53  light_BMM                 198403 non-null  float64       
 54  light_BMB                 0 non-null       float64       
 55  light_BLT                 198403 non-null  float64       
 56  light_BLM                 0 non-null       float64       
 57  light_BLB                 198403 non-null  float64       
 58  light_WRB                 198403 non-null  float64       
 59  light_WMB                 198403 non-null  float64       
 60  light_WLB                 198403 non-null  float64       
 61  light_WLF                 198403 non-null  float64       
 62  light_DoorRT              198403 non-null  float64       
 63  light_BTable              198403 non-null  float64       
 64  light_PRUR                198403 non-null  float64       
 65  light_PRUL                198403 non-null  float64       
 66  light_PRDR                198403 non-null  float64       
 67  light_PRDL                198403 non-null  float64       
 68  light_PLDR                198403 non-null  float64       
 69  light_PLDL                0 non-null       float64       
 70  light_Out                 198403 non-null  float64       
 71  outdoor_temperature       198403 non-null  float64       
 72  outdoor_humidity          198403 non-null  float64       
 73  outdoor_windgust          198403 non-null  float64       
 74  outdoor_windspeed         198403 non-null  float64       
 75  outdoor_winddir           198403 non-null  float64       
 76  outdoor_sealevelpressure  198403 non-null  float64       
 77  outdoor_dew               198403 non-null  float64       
 78  outdoor_cloudcover        198403 non-null  float64       
 79  outdoor_solarradiation    198403 non-null  float64       
 80  outdoor_solarenergy       198403 non-null  float64       
dtypes: datetime64[ns](1), float64(80)
memory usage: 122.6 MB
<class 'pandas.core.frame.DataFrame'>
Int64Index: 44180 entries, 153046 to 197225
Data columns (total 14 columns):
 #   Column                    Non-Null Count  Dtype  
---  ------                    --------------  -----  
 0   temperature_Main          44180 non-null  float64
 1   Occupancy                 44180 non-null  float64
 2   door_gap                  44180 non-null  float64
 3   window_gap                44180 non-null  float64
 4   outdoor_temperature       44180 non-null  float64
 5   outdoor_humidity          44180 non-null  float64
 6   outdoor_windgust          44180 non-null  float64
 7   outdoor_windspeed         44180 non-null  float64
 8   outdoor_winddir           44180 non-null  float64
 9   outdoor_sealevelpressure  44180 non-null  float64
 10  outdoor_dew               44180 non-null  float64
 11  outdoor_cloudcover        44180 non-null  float64
 12  outdoor_solarradiation    44180 non-null  float64
 13  outdoor_solarenergy       44180 non-null  float64
dtypes: float64(14)
memory usage: 5.1 MB
None
(4180, 14)
Running on: cuda
Epoch [1/1000], Training Loss: 6.6773, Validation Loss: 5.3746
Epoch [2/1000], Training Loss: 1.4671, Validation Loss: 1.5278
Epoch [3/1000], Training Loss: 0.4555, Validation Loss: 0.5631
Epoch [4/1000], Training Loss: 0.2129, Validation Loss: 0.3156
Epoch [5/1000], Training Loss: 0.1371, Validation Loss: 0.2249
Epoch [6/1000], Training Loss: 0.1029, Validation Loss: 0.1835
Epoch [7/1000], Training Loss: 0.0905, Validation Loss: 0.1586
Epoch [8/1000], Training Loss: 0.0778, Validation Loss: 0.1464
Epoch [9/1000], Training Loss: 0.0700, Validation Loss: 0.1373
Epoch [10/1000], Training Loss: 0.0608, Validation Loss: 0.1298
Epoch [11/1000], Training Loss: 0.0536, Validation Loss: 0.1240
Epoch [12/1000], Training Loss: 0.0479, Validation Loss: 0.1205
Epoch [13/1000], Training Loss: 0.0448, Validation Loss: 0.1179
Epoch [14/1000], Training Loss: 0.0428, Validation Loss: 0.1161
Epoch [15/1000], Training Loss: 0.0419, Validation Loss: 0.1141
Epoch [16/1000], Training Loss: 0.0411, Validation Loss: 0.1130
Epoch [17/1000], Training Loss: 0.0411, Validation Loss: 0.1126
Epoch [18/1000], Training Loss: 0.0403, Validation Loss: 0.1118
Epoch [19/1000], Training Loss: 0.0398, Validation Loss: 0.1109
Epoch [20/1000], Training Loss: 0.0395, Validation Loss: 0.1102
Epoch [21/1000], Training Loss: 0.0391, Validation Loss: 0.1096
Epoch [22/1000], Training Loss: 0.0386, Validation Loss: 0.1092
Epoch [23/1000], Training Loss: 0.0383, Validation Loss: 0.1089
Epoch [24/1000], Training Loss: 0.0377, Validation Loss: 0.1088
Epoch [25/1000], Training Loss: 0.0374, Validation Loss: 0.1085
Epoch [26/1000], Training Loss: 0.0374, Validation Loss: 0.1083
Epoch [27/1000], Training Loss: 0.0373, Validation Loss: 0.1084
Epoch [28/1000], Training Loss: 0.0375, Validation Loss: 0.1083
Epoch [29/1000], Training Loss: 0.0375, Validation Loss: 0.1084
Epoch [30/1000], Training Loss: 0.0374, Validation Loss: 0.1085
Epoch [31/1000], Training Loss: 0.0372, Validation Loss: 0.1086
Epoch [32/1000], Training Loss: 0.0369, Validation Loss: 0.1088
Epoch [33/1000], Training Loss: 0.0372, Validation Loss: 0.1091
Epoch [34/1000], Training Loss: 0.0374, Validation Loss: 0.1091
Epoch [35/1000], Training Loss: 0.0368, Validation Loss: 0.1092
Epoch [36/1000], Training Loss: 0.0365, Validation Loss: 0.1093
Epoch [37/1000], Training Loss: 0.0362, Validation Loss: 0.1094
Epoch [38/1000], Training Loss: 0.0361, Validation Loss: 0.1095
Epoch [39/1000], Training Loss: 0.0359, Validation Loss: 0.1096
Epoch [40/1000], Training Loss: 0.0353, Validation Loss: 0.1096
Epoch [41/1000], Training Loss: 0.0349, Validation Loss: 0.1096
Epoch [42/1000], Training Loss: 0.0344, Validation Loss: 0.1096
Epoch [43/1000], Training Loss: 0.0339, Validation Loss: 0.1098
Epoch [44/1000], Training Loss: 0.0333, Validation Loss: 0.1098
Epoch [45/1000], Training Loss: 0.0329, Validation Loss: 0.1098
Epoch [46/1000], Training Loss: 0.0327, Validation Loss: 0.1100
Epoch [47/1000], Training Loss: 0.0324, Validation Loss: 0.1102
Epoch [48/1000], Training Loss: 0.0323, Validation Loss: 0.1104
Epoch [49/1000], Training Loss: 0.0319, Validation Loss: 0.1104
Epoch [50/1000], Training Loss: 0.0315, Validation Loss: 0.1105
Epoch [51/1000], Training Loss: 0.0309, Validation Loss: 0.1099
Epoch [52/1000], Training Loss: 0.0306, Validation Loss: 0.1093
Epoch [53/1000], Training Loss: 0.0303, Validation Loss: 0.1089
Epoch [54/1000], Training Loss: 0.0304, Validation Loss: 0.1082
Epoch [55/1000], Training Loss: 0.0303, Validation Loss: 0.1077
Epoch [56/1000], Training Loss: 0.0302, Validation Loss: 0.1074
Epoch [57/1000], Training Loss: 0.0299, Validation Loss: 0.1072
Epoch [58/1000], Training Loss: 0.0294, Validation Loss: 0.1068
Epoch [59/1000], Training Loss: 0.0288, Validation Loss: 0.1065
Epoch [60/1000], Training Loss: 0.0285, Validation Loss: 0.1063
Epoch [61/1000], Training Loss: 0.0289, Validation Loss: 0.1056
Epoch [62/1000], Training Loss: 0.0295, Validation Loss: 0.1048
Epoch [63/1000], Training Loss: 0.0297, Validation Loss: 0.1043
Epoch [64/1000], Training Loss: 0.0299, Validation Loss: 0.1040
Epoch [65/1000], Training Loss: 0.0300, Validation Loss: 0.1035
Epoch [66/1000], Training Loss: 0.0300, Validation Loss: 0.1030
Epoch [67/1000], Training Loss: 0.0303, Validation Loss: 0.1020
Epoch [68/1000], Training Loss: 0.0298, Validation Loss: 0.1013
Epoch [69/1000], Training Loss: 0.0300, Validation Loss: 0.1007
Epoch [70/1000], Training Loss: 0.0300, Validation Loss: 0.1000
Epoch [71/1000], Training Loss: 0.0302, Validation Loss: 0.0994
Epoch [72/1000], Training Loss: 0.0305, Validation Loss: 0.0989
Epoch [73/1000], Training Loss: 0.0308, Validation Loss: 0.0986
Epoch [74/1000], Training Loss: 0.0315, Validation Loss: 0.0982
Epoch [75/1000], Training Loss: 0.0320, Validation Loss: 0.0978
Epoch [76/1000], Training Loss: 0.0324, Validation Loss: 0.0977
Epoch [77/1000], Training Loss: 0.0326, Validation Loss: 0.0975
Epoch [78/1000], Training Loss: 0.0328, Validation Loss: 0.0974
Epoch [79/1000], Training Loss: 0.0330, Validation Loss: 0.0972
Epoch [80/1000], Training Loss: 0.0334, Validation Loss: 0.0969
Epoch [81/1000], Training Loss: 0.0336, Validation Loss: 0.0966
Epoch [82/1000], Training Loss: 0.0338, Validation Loss: 0.0964
Epoch [83/1000], Training Loss: 0.0338, Validation Loss: 0.0962
Epoch [84/1000], Training Loss: 0.0339, Validation Loss: 0.0960
Epoch [85/1000], Training Loss: 0.0336, Validation Loss: 0.0960
Epoch [86/1000], Training Loss: 0.0334, Validation Loss: 0.0959
Epoch [87/1000], Training Loss: 0.0333, Validation Loss: 0.0958
Epoch [88/1000], Training Loss: 0.0332, Validation Loss: 0.0955
Epoch [89/1000], Training Loss: 0.0330, Validation Loss: 0.0953
Epoch [90/1000], Training Loss: 0.0330, Validation Loss: 0.0953
Epoch [91/1000], Training Loss: 0.0331, Validation Loss: 0.0954
Epoch [92/1000], Training Loss: 0.0331, Validation Loss: 0.0954
Epoch [93/1000], Training Loss: 0.0332, Validation Loss: 0.0954
Epoch [94/1000], Training Loss: 0.0334, Validation Loss: 0.0953
Epoch [95/1000], Training Loss: 0.0334, Validation Loss: 0.0952
Epoch [96/1000], Training Loss: 0.0335, Validation Loss: 0.0951
Epoch [97/1000], Training Loss: 0.0337, Validation Loss: 0.0951
Epoch [98/1000], Training Loss: 0.0337, Validation Loss: 0.0949
Epoch [99/1000], Training Loss: 0.0338, Validation Loss: 0.0950
Epoch [100/1000], Training Loss: 0.0338, Validation Loss: 0.0949
Epoch [101/1000], Training Loss: 0.0339, Validation Loss: 0.0949
Epoch [102/1000], Training Loss: 0.0337, Validation Loss: 0.0947
Epoch [103/1000], Training Loss: 0.0338, Validation Loss: 0.0947
Epoch [104/1000], Training Loss: 0.0337, Validation Loss: 0.0947
Epoch [105/1000], Training Loss: 0.0338, Validation Loss: 0.0947
Epoch [106/1000], Training Loss: 0.0337, Validation Loss: 0.0946
Epoch [107/1000], Training Loss: 0.0339, Validation Loss: 0.0946
Epoch [108/1000], Training Loss: 0.0338, Validation Loss: 0.0945
Epoch [109/1000], Training Loss: 0.0338, Validation Loss: 0.0946
Epoch [110/1000], Training Loss: 0.0339, Validation Loss: 0.0946
Epoch [111/1000], Training Loss: 0.0336, Validation Loss: 0.0945
Epoch [112/1000], Training Loss: 0.0334, Validation Loss: 0.0943
Epoch [113/1000], Training Loss: 0.0336, Validation Loss: 0.0942
Epoch [114/1000], Training Loss: 0.0335, Validation Loss: 0.0939
Epoch [115/1000], Training Loss: 0.0335, Validation Loss: 0.0936
Epoch [116/1000], Training Loss: 0.0337, Validation Loss: 0.0932
Epoch [117/1000], Training Loss: 0.0339, Validation Loss: 0.0929
Epoch [118/1000], Training Loss: 0.0334, Validation Loss: 0.0926
Epoch [119/1000], Training Loss: 0.0330, Validation Loss: 0.0921
Epoch [120/1000], Training Loss: 0.0323, Validation Loss: 0.0919
Epoch [121/1000], Training Loss: 0.0317, Validation Loss: 0.0916
Epoch [122/1000], Training Loss: 0.0316, Validation Loss: 0.0914
Epoch [123/1000], Training Loss: 0.0316, Validation Loss: 0.0913
Epoch [124/1000], Training Loss: 0.0315, Validation Loss: 0.0912
Epoch [125/1000], Training Loss: 0.0314, Validation Loss: 0.0912
Epoch [126/1000], Training Loss: 0.0313, Validation Loss: 0.0910
Epoch [127/1000], Training Loss: 0.0310, Validation Loss: 0.0909
Epoch [128/1000], Training Loss: 0.0309, Validation Loss: 0.0907
Epoch [129/1000], Training Loss: 0.0306, Validation Loss: 0.0906
Epoch [130/1000], Training Loss: 0.0306, Validation Loss: 0.0905
Epoch [131/1000], Training Loss: 0.0305, Validation Loss: 0.0905
Epoch [132/1000], Training Loss: 0.0304, Validation Loss: 0.0904
Epoch [133/1000], Training Loss: 0.0303, Validation Loss: 0.0903
Epoch [134/1000], Training Loss: 0.0304, Validation Loss: 0.0902
Epoch [135/1000], Training Loss: 0.0302, Validation Loss: 0.0901
Epoch [136/1000], Training Loss: 0.0300, Validation Loss: 0.0900
Epoch [137/1000], Training Loss: 0.0298, Validation Loss: 0.0899
Epoch [138/1000], Training Loss: 0.0297, Validation Loss: 0.0897
Epoch [139/1000], Training Loss: 0.0295, Validation Loss: 0.0896
Epoch [140/1000], Training Loss: 0.0293, Validation Loss: 0.0895
Epoch [141/1000], Training Loss: 0.0292, Validation Loss: 0.0893
Epoch [142/1000], Training Loss: 0.0291, Validation Loss: 0.0892
Epoch [143/1000], Training Loss: 0.0287, Validation Loss: 0.0892
Epoch [144/1000], Training Loss: 0.0285, Validation Loss: 0.0890
Epoch [145/1000], Training Loss: 0.0284, Validation Loss: 0.0890
Epoch [146/1000], Training Loss: 0.0281, Validation Loss: 0.0888
Epoch [147/1000], Training Loss: 0.0279, Validation Loss: 0.0889
Epoch [148/1000], Training Loss: 0.0280, Validation Loss: 0.0890
Epoch [149/1000], Training Loss: 0.0280, Validation Loss: 0.0889
Epoch [150/1000], Training Loss: 0.0278, Validation Loss: 0.0889
Epoch [151/1000], Training Loss: 0.0278, Validation Loss: 0.0890
Epoch [152/1000], Training Loss: 0.0276, Validation Loss: 0.0889
Epoch [153/1000], Training Loss: 0.0276, Validation Loss: 0.0889
Epoch [154/1000], Training Loss: 0.0276, Validation Loss: 0.0889
Epoch [155/1000], Training Loss: 0.0275, Validation Loss: 0.0889
Epoch [156/1000], Training Loss: 0.0272, Validation Loss: 0.0890
Epoch [157/1000], Training Loss: 0.0273, Validation Loss: 0.0890
Epoch [158/1000], Training Loss: 0.0272, Validation Loss: 0.0892
Epoch [159/1000], Training Loss: 0.0270, Validation Loss: 0.0892
Epoch [160/1000], Training Loss: 0.0269, Validation Loss: 0.0892
Epoch [161/1000], Training Loss: 0.0268, Validation Loss: 0.0893
Epoch [162/1000], Training Loss: 0.0267, Validation Loss: 0.0892
Epoch [163/1000], Training Loss: 0.0265, Validation Loss: 0.0892
Epoch [164/1000], Training Loss: 0.0267, Validation Loss: 0.0892
Epoch [165/1000], Training Loss: 0.0267, Validation Loss: 0.0892
Epoch [166/1000], Training Loss: 0.0267, Validation Loss: 0.0893
Epoch [167/1000], Training Loss: 0.0266, Validation Loss: 0.0894
Epoch [168/1000], Training Loss: 0.0266, Validation Loss: 0.0894
Epoch [169/1000], Training Loss: 0.0266, Validation Loss: 0.0895
Epoch [170/1000], Training Loss: 0.0265, Validation Loss: 0.0895
Epoch [171/1000], Training Loss: 0.0264, Validation Loss: 0.0896
Epoch [172/1000], Training Loss: 0.0264, Validation Loss: 0.0897
Epoch [173/1000], Training Loss: 0.0265, Validation Loss: 0.0898
Epoch [174/1000], Training Loss: 0.0265, Validation Loss: 0.0898
Epoch [175/1000], Training Loss: 0.0266, Validation Loss: 0.0899
Epoch [176/1000], Training Loss: 0.0265, Validation Loss: 0.0899
Epoch [177/1000], Training Loss: 0.0265, Validation Loss: 0.0900
Epoch [178/1000], Training Loss: 0.0266, Validation Loss: 0.0900
Epoch [179/1000], Training Loss: 0.0265, Validation Loss: 0.0901
Epoch [180/1000], Training Loss: 0.0266, Validation Loss: 0.0901
Epoch [181/1000], Training Loss: 0.0265, Validation Loss: 0.0902
Epoch [182/1000], Training Loss: 0.0265, Validation Loss: 0.0902
Epoch [183/1000], Training Loss: 0.0266, Validation Loss: 0.0902
Epoch [184/1000], Training Loss: 0.0267, Validation Loss: 0.0904
Epoch [185/1000], Training Loss: 0.0267, Validation Loss: 0.0904
Epoch [186/1000], Training Loss: 0.0266, Validation Loss: 0.0905
Epoch [187/1000], Training Loss: 0.0266, Validation Loss: 0.0905
Epoch [188/1000], Training Loss: 0.0266, Validation Loss: 0.0906
Epoch [189/1000], Training Loss: 0.0265, Validation Loss: 0.0907
Epoch [190/1000], Training Loss: 0.0264, Validation Loss: 0.0907
Epoch [191/1000], Training Loss: 0.0265, Validation Loss: 0.0907
Epoch [192/1000], Training Loss: 0.0266, Validation Loss: 0.0908
Epoch [193/1000], Training Loss: 0.0264, Validation Loss: 0.0907
Epoch [194/1000], Training Loss: 0.0263, Validation Loss: 0.0906
Epoch [195/1000], Training Loss: 0.0264, Validation Loss: 0.0907
Epoch [196/1000], Training Loss: 0.0264, Validation Loss: 0.0907
Epoch [197/1000], Training Loss: 0.0264, Validation Loss: 0.0907
Epoch [198/1000], Training Loss: 0.0265, Validation Loss: 0.0907
Epoch [199/1000], Training Loss: 0.0264, Validation Loss: 0.0907
Epoch [200/1000], Training Loss: 0.0264, Validation Loss: 0.0908
Epoch [201/1000], Training Loss: 0.0265, Validation Loss: 0.0908
Epoch [202/1000], Training Loss: 0.0264, Validation Loss: 0.0910
Epoch [203/1000], Training Loss: 0.0266, Validation Loss: 0.0910
Epoch [204/1000], Training Loss: 0.0265, Validation Loss: 0.0911
Epoch [205/1000], Training Loss: 0.0265, Validation Loss: 0.0912
Epoch [206/1000], Training Loss: 0.0265, Validation Loss: 0.0912
Epoch [207/1000], Training Loss: 0.0265, Validation Loss: 0.0912
Epoch [208/1000], Training Loss: 0.0265, Validation Loss: 0.0913
Epoch [209/1000], Training Loss: 0.0266, Validation Loss: 0.0913
Epoch [210/1000], Training Loss: 0.0268, Validation Loss: 0.0915
Epoch [211/1000], Training Loss: 0.0267, Validation Loss: 0.0916
Epoch [212/1000], Training Loss: 0.0267, Validation Loss: 0.0916
Epoch [213/1000], Training Loss: 0.0268, Validation Loss: 0.0916
Epoch [214/1000], Training Loss: 0.0268, Validation Loss: 0.0917
Epoch [215/1000], Training Loss: 0.0268, Validation Loss: 0.0917
Epoch [216/1000], Training Loss: 0.0267, Validation Loss: 0.0918
Epoch [217/1000], Training Loss: 0.0268, Validation Loss: 0.0918
Epoch [218/1000], Training Loss: 0.0267, Validation Loss: 0.0918
Epoch [219/1000], Training Loss: 0.0266, Validation Loss: 0.0919
Epoch [220/1000], Training Loss: 0.0266, Validation Loss: 0.0919
Epoch [221/1000], Training Loss: 0.0266, Validation Loss: 0.0920
Epoch [222/1000], Training Loss: 0.0265, Validation Loss: 0.0920
Epoch [223/1000], Training Loss: 0.0265, Validation Loss: 0.0920
Epoch [224/1000], Training Loss: 0.0264, Validation Loss: 0.0921
Epoch [225/1000], Training Loss: 0.0264, Validation Loss: 0.0921
Epoch [226/1000], Training Loss: 0.0264, Validation Loss: 0.0922
Epoch [227/1000], Training Loss: 0.0263, Validation Loss: 0.0922
Epoch [228/1000], Training Loss: 0.0261, Validation Loss: 0.0922
Epoch [229/1000], Training Loss: 0.0264, Validation Loss: 0.0923
Epoch [230/1000], Training Loss: 0.0263, Validation Loss: 0.0923
Epoch [231/1000], Training Loss: 0.0263, Validation Loss: 0.0923
Epoch [232/1000], Training Loss: 0.0262, Validation Loss: 0.0923
Epoch [233/1000], Training Loss: 0.0262, Validation Loss: 0.0922
Epoch [234/1000], Training Loss: 0.0263, Validation Loss: 0.0922
Epoch [235/1000], Training Loss: 0.0262, Validation Loss: 0.0922
Epoch [236/1000], Training Loss: 0.0262, Validation Loss: 0.0921
Epoch [237/1000], Training Loss: 0.0260, Validation Loss: 0.0920
Epoch [238/1000], Training Loss: 0.0258, Validation Loss: 0.0920
Epoch [239/1000], Training Loss: 0.0255, Validation Loss: 0.0919
Epoch [240/1000], Training Loss: 0.0253, Validation Loss: 0.0919
Epoch [241/1000], Training Loss: 0.0251, Validation Loss: 0.0918
Epoch [242/1000], Training Loss: 0.0250, Validation Loss: 0.0917
Epoch [243/1000], Training Loss: 0.0249, Validation Loss: 0.0916
Epoch [244/1000], Training Loss: 0.0248, Validation Loss: 0.0916
Epoch [245/1000], Training Loss: 0.0248, Validation Loss: 0.0915
Epoch [246/1000], Training Loss: 0.0247, Validation Loss: 0.0914
Epoch [247/1000], Training Loss: 0.0247, Validation Loss: 0.0914
Epoch [248/1000], Training Loss: 0.0248, Validation Loss: 0.0913
Epoch [249/1000], Training Loss: 0.0247, Validation Loss: 0.0911
Epoch [250/1000], Training Loss: 0.0247, Validation Loss: 0.0910
Epoch [251/1000], Training Loss: 0.0246, Validation Loss: 0.0909
Epoch [252/1000], Training Loss: 0.0246, Validation Loss: 0.0908
Epoch [253/1000], Training Loss: 0.0247, Validation Loss: 0.0907
Epoch [254/1000], Training Loss: 0.0246, Validation Loss: 0.0905
Epoch [255/1000], Training Loss: 0.0247, Validation Loss: 0.0903
Epoch [256/1000], Training Loss: 0.0246, Validation Loss: 0.0902
Epoch [257/1000], Training Loss: 0.0246, Validation Loss: 0.0901
Epoch [258/1000], Training Loss: 0.0245, Validation Loss: 0.0900
Epoch [259/1000], Training Loss: 0.0245, Validation Loss: 0.0898
Epoch [260/1000], Training Loss: 0.0244, Validation Loss: 0.0897
Epoch [261/1000], Training Loss: 0.0243, Validation Loss: 0.0896
Epoch [262/1000], Training Loss: 0.0243, Validation Loss: 0.0894
Epoch [263/1000], Training Loss: 0.0243, Validation Loss: 0.0893
Epoch [264/1000], Training Loss: 0.0243, Validation Loss: 0.0892
Epoch [265/1000], Training Loss: 0.0243, Validation Loss: 0.0890
Epoch [266/1000], Training Loss: 0.0242, Validation Loss: 0.0889
Epoch [267/1000], Training Loss: 0.0241, Validation Loss: 0.0888
Epoch [268/1000], Training Loss: 0.0240, Validation Loss: 0.0887
Epoch [269/1000], Training Loss: 0.0239, Validation Loss: 0.0886
Epoch [270/1000], Training Loss: 0.0239, Validation Loss: 0.0883
Epoch [271/1000], Training Loss: 0.0238, Validation Loss: 0.0883
Epoch [272/1000], Training Loss: 0.0239, Validation Loss: 0.0881
Epoch [273/1000], Training Loss: 0.0237, Validation Loss: 0.0880
Epoch [274/1000], Training Loss: 0.0237, Validation Loss: 0.0878
Epoch [275/1000], Training Loss: 0.0236, Validation Loss: 0.0877
Epoch [276/1000], Training Loss: 0.0235, Validation Loss: 0.0875
Epoch [277/1000], Training Loss: 0.0234, Validation Loss: 0.0874
Epoch [278/1000], Training Loss: 0.0233, Validation Loss: 0.0872
Epoch [279/1000], Training Loss: 0.0233, Validation Loss: 0.0871
Epoch [280/1000], Training Loss: 0.0233, Validation Loss: 0.0869
Epoch [281/1000], Training Loss: 0.0233, Validation Loss: 0.0868
Epoch [282/1000], Training Loss: 0.0232, Validation Loss: 0.0867
Epoch [283/1000], Training Loss: 0.0229, Validation Loss: 0.0865
Epoch [284/1000], Training Loss: 0.0229, Validation Loss: 0.0864
Epoch [285/1000], Training Loss: 0.0229, Validation Loss: 0.0864
Epoch [286/1000], Training Loss: 0.0228, Validation Loss: 0.0864
Epoch [287/1000], Training Loss: 0.0227, Validation Loss: 0.0864
Epoch [288/1000], Training Loss: 0.0227, Validation Loss: 0.0864
Epoch [289/1000], Training Loss: 0.0226, Validation Loss: 0.0864
Epoch [290/1000], Training Loss: 0.0227, Validation Loss: 0.0864
Epoch [291/1000], Training Loss: 0.0225, Validation Loss: 0.0863
Epoch [292/1000], Training Loss: 0.0226, Validation Loss: 0.0864
Epoch [293/1000], Training Loss: 0.0226, Validation Loss: 0.0864
Epoch [294/1000], Training Loss: 0.0225, Validation Loss: 0.0863
Epoch [295/1000], Training Loss: 0.0225, Validation Loss: 0.0863
Epoch [296/1000], Training Loss: 0.0224, Validation Loss: 0.0864
Epoch [297/1000], Training Loss: 0.0223, Validation Loss: 0.0863
Epoch [298/1000], Training Loss: 0.0224, Validation Loss: 0.0864
Epoch [299/1000], Training Loss: 0.0224, Validation Loss: 0.0864
Epoch [300/1000], Training Loss: 0.0223, Validation Loss: 0.0864
Epoch [301/1000], Training Loss: 0.0223, Validation Loss: 0.0863
Epoch [302/1000], Training Loss: 0.0222, Validation Loss: 0.0863
Epoch [303/1000], Training Loss: 0.0223, Validation Loss: 0.0863
Epoch [304/1000], Training Loss: 0.0224, Validation Loss: 0.0863
Epoch [305/1000], Training Loss: 0.0226, Validation Loss: 0.0863
Epoch [306/1000], Training Loss: 0.0224, Validation Loss: 0.0862
Epoch [307/1000], Training Loss: 0.0224, Validation Loss: 0.0862
Epoch [308/1000], Training Loss: 0.0224, Validation Loss: 0.0862
Epoch [309/1000], Training Loss: 0.0223, Validation Loss: 0.0861
Epoch [310/1000], Training Loss: 0.0223, Validation Loss: 0.0861
Epoch [311/1000], Training Loss: 0.0222, Validation Loss: 0.0861
Epoch [312/1000], Training Loss: 0.0222, Validation Loss: 0.0861
Epoch [313/1000], Training Loss: 0.0222, Validation Loss: 0.0861
Epoch [314/1000], Training Loss: 0.0221, Validation Loss: 0.0861
Epoch [315/1000], Training Loss: 0.0221, Validation Loss: 0.0861
Epoch [316/1000], Training Loss: 0.0222, Validation Loss: 0.0862
Epoch [317/1000], Training Loss: 0.0221, Validation Loss: 0.0863
Epoch [318/1000], Training Loss: 0.0220, Validation Loss: 0.0864
Epoch [319/1000], Training Loss: 0.0218, Validation Loss: 0.0863
Epoch [320/1000], Training Loss: 0.0219, Validation Loss: 0.0863
Epoch [321/1000], Training Loss: 0.0220, Validation Loss: 0.0863
Epoch [322/1000], Training Loss: 0.0218, Validation Loss: 0.0862
Epoch [323/1000], Training Loss: 0.0219, Validation Loss: 0.0863
Epoch [324/1000], Training Loss: 0.0218, Validation Loss: 0.0863
Epoch [325/1000], Training Loss: 0.0218, Validation Loss: 0.0864
Epoch [326/1000], Training Loss: 0.0217, Validation Loss: 0.0865
Epoch [327/1000], Training Loss: 0.0217, Validation Loss: 0.0865
Epoch [328/1000], Training Loss: 0.0215, Validation Loss: 0.0864
Epoch [329/1000], Training Loss: 0.0216, Validation Loss: 0.0865
Epoch [330/1000], Training Loss: 0.0218, Validation Loss: 0.0865
Epoch [331/1000], Training Loss: 0.0218, Validation Loss: 0.0865
Epoch [332/1000], Training Loss: 0.0216, Validation Loss: 0.0865
Epoch [333/1000], Training Loss: 0.0216, Validation Loss: 0.0865
Epoch [334/1000], Training Loss: 0.0216, Validation Loss: 0.0866
Epoch [335/1000], Training Loss: 0.0214, Validation Loss: 0.0866
Epoch [336/1000], Training Loss: 0.0213, Validation Loss: 0.0867
Epoch [337/1000], Training Loss: 0.0214, Validation Loss: 0.0867
Epoch [338/1000], Training Loss: 0.0212, Validation Loss: 0.0866
Epoch [339/1000], Training Loss: 0.0212, Validation Loss: 0.0866
Epoch [340/1000], Training Loss: 0.0211, Validation Loss: 0.0865
Epoch [341/1000], Training Loss: 0.0209, Validation Loss: 0.0864
Epoch [342/1000], Training Loss: 0.0208, Validation Loss: 0.0865
Epoch [343/1000], Training Loss: 0.0207, Validation Loss: 0.0865
Epoch [344/1000], Training Loss: 0.0206, Validation Loss: 0.0865
Epoch [345/1000], Training Loss: 0.0205, Validation Loss: 0.0865
Epoch [346/1000], Training Loss: 0.0205, Validation Loss: 0.0865
Epoch [347/1000], Training Loss: 0.0206, Validation Loss: 0.0866
Epoch [348/1000], Training Loss: 0.0205, Validation Loss: 0.0867
Epoch [349/1000], Training Loss: 0.0205, Validation Loss: 0.0867
Epoch [350/1000], Training Loss: 0.0204, Validation Loss: 0.0867
Epoch [351/1000], Training Loss: 0.0203, Validation Loss: 0.0867
Epoch [352/1000], Training Loss: 0.0203, Validation Loss: 0.0867
Epoch [353/1000], Training Loss: 0.0204, Validation Loss: 0.0867
Epoch [354/1000], Training Loss: 0.0203, Validation Loss: 0.0868
Epoch [355/1000], Training Loss: 0.0203, Validation Loss: 0.0868
Epoch [356/1000], Training Loss: 0.0202, Validation Loss: 0.0869
Epoch [357/1000], Training Loss: 0.0203, Validation Loss: 0.0868
Epoch [358/1000], Training Loss: 0.0202, Validation Loss: 0.0868
Epoch [359/1000], Training Loss: 0.0202, Validation Loss: 0.0868
Epoch [360/1000], Training Loss: 0.0202, Validation Loss: 0.0867
Epoch [361/1000], Training Loss: 0.0202, Validation Loss: 0.0867
Epoch [362/1000], Training Loss: 0.0201, Validation Loss: 0.0866
Epoch [363/1000], Training Loss: 0.0201, Validation Loss: 0.0866
Epoch [364/1000], Training Loss: 0.0201, Validation Loss: 0.0866
Epoch [365/1000], Training Loss: 0.0200, Validation Loss: 0.0866
Epoch [366/1000], Training Loss: 0.0201, Validation Loss: 0.0865
Epoch [367/1000], Training Loss: 0.0201, Validation Loss: 0.0865
Epoch [368/1000], Training Loss: 0.0202, Validation Loss: 0.0865
Epoch [369/1000], Training Loss: 0.0202, Validation Loss: 0.0865
Epoch [370/1000], Training Loss: 0.0202, Validation Loss: 0.0864
Epoch [371/1000], Training Loss: 0.0202, Validation Loss: 0.0863
Epoch [372/1000], Training Loss: 0.0202, Validation Loss: 0.0864
Epoch [373/1000], Training Loss: 0.0201, Validation Loss: 0.0864
Epoch [374/1000], Training Loss: 0.0200, Validation Loss: 0.0863
Epoch [375/1000], Training Loss: 0.0200, Validation Loss: 0.0863
Epoch [376/1000], Training Loss: 0.0200, Validation Loss: 0.0863
Epoch [377/1000], Training Loss: 0.0200, Validation Loss: 0.0863
Epoch [378/1000], Training Loss: 0.0200, Validation Loss: 0.0863
Epoch [379/1000], Training Loss: 0.0199, Validation Loss: 0.0862
Epoch [380/1000], Training Loss: 0.0200, Validation Loss: 0.0862
Epoch [381/1000], Training Loss: 0.0200, Validation Loss: 0.0861
Epoch [382/1000], Training Loss: 0.0200, Validation Loss: 0.0861
Epoch [383/1000], Training Loss: 0.0200, Validation Loss: 0.0860
Epoch [384/1000], Training Loss: 0.0199, Validation Loss: 0.0860
Epoch [385/1000], Training Loss: 0.0199, Validation Loss: 0.0859
Epoch [386/1000], Training Loss: 0.0199, Validation Loss: 0.0858
Epoch [387/1000], Training Loss: 0.0199, Validation Loss: 0.0858
Epoch [388/1000], Training Loss: 0.0199, Validation Loss: 0.0857
Epoch [389/1000], Training Loss: 0.0198, Validation Loss: 0.0857
Epoch [390/1000], Training Loss: 0.0199, Validation Loss: 0.0857
Epoch [391/1000], Training Loss: 0.0198, Validation Loss: 0.0856
Epoch [392/1000], Training Loss: 0.0197, Validation Loss: 0.0856
Epoch [393/1000], Training Loss: 0.0197, Validation Loss: 0.0857
Epoch [394/1000], Training Loss: 0.0197, Validation Loss: 0.0856
Epoch [395/1000], Training Loss: 0.0197, Validation Loss: 0.0856
Epoch [396/1000], Training Loss: 0.0196, Validation Loss: 0.0857
Epoch [397/1000], Training Loss: 0.0197, Validation Loss: 0.0857
Epoch [398/1000], Training Loss: 0.0197, Validation Loss: 0.0857
Epoch [399/1000], Training Loss: 0.0196, Validation Loss: 0.0857
Epoch [400/1000], Training Loss: 0.0196, Validation Loss: 0.0857
Epoch [401/1000], Training Loss: 0.0196, Validation Loss: 0.0857
Epoch [402/1000], Training Loss: 0.0195, Validation Loss: 0.0857
Epoch [403/1000], Training Loss: 0.0194, Validation Loss: 0.0857
Epoch [404/1000], Training Loss: 0.0194, Validation Loss: 0.0858
Epoch [405/1000], Training Loss: 0.0194, Validation Loss: 0.0858
Epoch [406/1000], Training Loss: 0.0194, Validation Loss: 0.0858
Epoch [407/1000], Training Loss: 0.0193, Validation Loss: 0.0858
Epoch [408/1000], Training Loss: 0.0194, Validation Loss: 0.0859
Epoch [409/1000], Training Loss: 0.0193, Validation Loss: 0.0859
Epoch [410/1000], Training Loss: 0.0193, Validation Loss: 0.0859
Epoch [411/1000], Training Loss: 0.0194, Validation Loss: 0.0860
Epoch [412/1000], Training Loss: 0.0194, Validation Loss: 0.0859
Epoch [413/1000], Training Loss: 0.0193, Validation Loss: 0.0859
Epoch [414/1000], Training Loss: 0.0193, Validation Loss: 0.0859
Epoch [415/1000], Training Loss: 0.0192, Validation Loss: 0.0859
Epoch [416/1000], Training Loss: 0.0191, Validation Loss: 0.0860
Epoch [417/1000], Training Loss: 0.0191, Validation Loss: 0.0860
Epoch [418/1000], Training Loss: 0.0192, Validation Loss: 0.0861
Epoch [419/1000], Training Loss: 0.0192, Validation Loss: 0.0861
Epoch [420/1000], Training Loss: 0.0192, Validation Loss: 0.0862
Epoch [421/1000], Training Loss: 0.0193, Validation Loss: 0.0862
Epoch [422/1000], Training Loss: 0.0193, Validation Loss: 0.0862
Epoch [423/1000], Training Loss: 0.0193, Validation Loss: 0.0863
Epoch [424/1000], Training Loss: 0.0192, Validation Loss: 0.0863
Epoch [425/1000], Training Loss: 0.0193, Validation Loss: 0.0865
Epoch [426/1000], Training Loss: 0.0193, Validation Loss: 0.0866
Epoch [427/1000], Training Loss: 0.0194, Validation Loss: 0.0867
Epoch [428/1000], Training Loss: 0.0194, Validation Loss: 0.0868
Epoch [429/1000], Training Loss: 0.0194, Validation Loss: 0.0867
Epoch [430/1000], Training Loss: 0.0193, Validation Loss: 0.0868
Epoch [431/1000], Training Loss: 0.0193, Validation Loss: 0.0868
Epoch [432/1000], Training Loss: 0.0192, Validation Loss: 0.0869
Epoch [433/1000], Training Loss: 0.0191, Validation Loss: 0.0869
Epoch [434/1000], Training Loss: 0.0193, Validation Loss: 0.0869
Epoch [435/1000], Training Loss: 0.0192, Validation Loss: 0.0869
Epoch [436/1000], Training Loss: 0.0193, Validation Loss: 0.0871
Epoch [437/1000], Training Loss: 0.0193, Validation Loss: 0.0871
Epoch [438/1000], Training Loss: 0.0193, Validation Loss: 0.0871
Epoch [439/1000], Training Loss: 0.0193, Validation Loss: 0.0872
Epoch [440/1000], Training Loss: 0.0193, Validation Loss: 0.0872
Epoch [441/1000], Training Loss: 0.0192, Validation Loss: 0.0872
Epoch [442/1000], Training Loss: 0.0192, Validation Loss: 0.0872
Epoch [443/1000], Training Loss: 0.0192, Validation Loss: 0.0872
Epoch [444/1000], Training Loss: 0.0192, Validation Loss: 0.0872
Epoch [445/1000], Training Loss: 0.0192, Validation Loss: 0.0872
Epoch [446/1000], Training Loss: 0.0192, Validation Loss: 0.0872
Epoch [447/1000], Training Loss: 0.0192, Validation Loss: 0.0873
Epoch [448/1000], Training Loss: 0.0191, Validation Loss: 0.0872
Epoch [449/1000], Training Loss: 0.0192, Validation Loss: 0.0873
Epoch [450/1000], Training Loss: 0.0191, Validation Loss: 0.0872
Epoch [451/1000], Training Loss: 0.0192, Validation Loss: 0.0873
Epoch [452/1000], Training Loss: 0.0191, Validation Loss: 0.0872
Epoch [453/1000], Training Loss: 0.0191, Validation Loss: 0.0873
Epoch [454/1000], Training Loss: 0.0190, Validation Loss: 0.0873
Epoch [455/1000], Training Loss: 0.0190, Validation Loss: 0.0873
Epoch [456/1000], Training Loss: 0.0190, Validation Loss: 0.0874
Epoch [457/1000], Training Loss: 0.0190, Validation Loss: 0.0874
Epoch [458/1000], Training Loss: 0.0190, Validation Loss: 0.0874
Epoch [459/1000], Training Loss: 0.0190, Validation Loss: 0.0874
Epoch [460/1000], Training Loss: 0.0190, Validation Loss: 0.0875
Epoch [461/1000], Training Loss: 0.0190, Validation Loss: 0.0874
Epoch [462/1000], Training Loss: 0.0189, Validation Loss: 0.0875
Epoch [463/1000], Training Loss: 0.0190, Validation Loss: 0.0876
Epoch [464/1000], Training Loss: 0.0189, Validation Loss: 0.0876
Epoch [465/1000], Training Loss: 0.0189, Validation Loss: 0.0876
Epoch [466/1000], Training Loss: 0.0189, Validation Loss: 0.0877
Epoch [467/1000], Training Loss: 0.0189, Validation Loss: 0.0877
Epoch [468/1000], Training Loss: 0.0189, Validation Loss: 0.0877
Epoch [469/1000], Training Loss: 0.0189, Validation Loss: 0.0877
Epoch [470/1000], Training Loss: 0.0189, Validation Loss: 0.0877
Epoch [471/1000], Training Loss: 0.0189, Validation Loss: 0.0877
Epoch [472/1000], Training Loss: 0.0188, Validation Loss: 0.0877
Epoch [473/1000], Training Loss: 0.0187, Validation Loss: 0.0877
Epoch [474/1000], Training Loss: 0.0188, Validation Loss: 0.0878
Epoch [475/1000], Training Loss: 0.0187, Validation Loss: 0.0878
Epoch [476/1000], Training Loss: 0.0187, Validation Loss: 0.0878
Epoch [477/1000], Training Loss: 0.0187, Validation Loss: 0.0878
Epoch [478/1000], Training Loss: 0.0187, Validation Loss: 0.0879
Epoch [479/1000], Training Loss: 0.0188, Validation Loss: 0.0878
Epoch [480/1000], Training Loss: 0.0187, Validation Loss: 0.0878
Epoch [481/1000], Training Loss: 0.0187, Validation Loss: 0.0878
Epoch [482/1000], Training Loss: 0.0186, Validation Loss: 0.0878
Epoch [483/1000], Training Loss: 0.0185, Validation Loss: 0.0878
Epoch [484/1000], Training Loss: 0.0186, Validation Loss: 0.0878
Epoch [485/1000], Training Loss: 0.0185, Validation Loss: 0.0877
Epoch [486/1000], Training Loss: 0.0187, Validation Loss: 0.0878
Epoch [487/1000], Training Loss: 0.0185, Validation Loss: 0.0877
Epoch [488/1000], Training Loss: 0.0186, Validation Loss: 0.0877
Epoch [489/1000], Training Loss: 0.0186, Validation Loss: 0.0877
Epoch [490/1000], Training Loss: 0.0185, Validation Loss: 0.0877
Epoch [491/1000], Training Loss: 0.0186, Validation Loss: 0.0877
Epoch [492/1000], Training Loss: 0.0186, Validation Loss: 0.0877
Epoch [493/1000], Training Loss: 0.0185, Validation Loss: 0.0876
Epoch [494/1000], Training Loss: 0.0185, Validation Loss: 0.0876
Epoch [495/1000], Training Loss: 0.0187, Validation Loss: 0.0876
Epoch [496/1000], Training Loss: 0.0186, Validation Loss: 0.0876
Epoch [497/1000], Training Loss: 0.0186, Validation Loss: 0.0876
Epoch [498/1000], Training Loss: 0.0186, Validation Loss: 0.0876
Epoch [499/1000], Training Loss: 0.0187, Validation Loss: 0.0876
Epoch [500/1000], Training Loss: 0.0187, Validation Loss: 0.0876
Epoch [501/1000], Training Loss: 0.0188, Validation Loss: 0.0877
Epoch [502/1000], Training Loss: 0.0188, Validation Loss: 0.0876
Epoch [503/1000], Training Loss: 0.0187, Validation Loss: 0.0877
Epoch [504/1000], Training Loss: 0.0188, Validation Loss: 0.0877
Epoch [505/1000], Training Loss: 0.0188, Validation Loss: 0.0877
Epoch [506/1000], Training Loss: 0.0187, Validation Loss: 0.0877
Epoch [507/1000], Training Loss: 0.0189, Validation Loss: 0.0877
Epoch [508/1000], Training Loss: 0.0188, Validation Loss: 0.0877
Epoch [509/1000], Training Loss: 0.0188, Validation Loss: 0.0877
Epoch [510/1000], Training Loss: 0.0188, Validation Loss: 0.0877
Epoch [511/1000], Training Loss: 0.0188, Validation Loss: 0.0877
Epoch [512/1000], Training Loss: 0.0188, Validation Loss: 0.0878
Epoch [513/1000], Training Loss: 0.0188, Validation Loss: 0.0878
Epoch [514/1000], Training Loss: 0.0189, Validation Loss: 0.0877
Epoch [515/1000], Training Loss: 0.0188, Validation Loss: 0.0878
Epoch [516/1000], Training Loss: 0.0189, Validation Loss: 0.0878
Epoch [517/1000], Training Loss: 0.0189, Validation Loss: 0.0878
Epoch [518/1000], Training Loss: 0.0189, Validation Loss: 0.0879
Epoch [519/1000], Training Loss: 0.0188, Validation Loss: 0.0879
Epoch [520/1000], Training Loss: 0.0188, Validation Loss: 0.0879
Epoch [521/1000], Training Loss: 0.0188, Validation Loss: 0.0879
Epoch [522/1000], Training Loss: 0.0189, Validation Loss: 0.0880
Epoch [523/1000], Training Loss: 0.0189, Validation Loss: 0.0879
Epoch [524/1000], Training Loss: 0.0188, Validation Loss: 0.0879
Epoch [525/1000], Training Loss: 0.0188, Validation Loss: 0.0880
Epoch [526/1000], Training Loss: 0.0188, Validation Loss: 0.0880
Epoch [527/1000], Training Loss: 0.0188, Validation Loss: 0.0880
Epoch [528/1000], Training Loss: 0.0188, Validation Loss: 0.0880
Epoch [529/1000], Training Loss: 0.0188, Validation Loss: 0.0880
Epoch [530/1000], Training Loss: 0.0189, Validation Loss: 0.0880
Epoch [531/1000], Training Loss: 0.0188, Validation Loss: 0.0880
Epoch [532/1000], Training Loss: 0.0188, Validation Loss: 0.0879
Epoch [533/1000], Training Loss: 0.0189, Validation Loss: 0.0880
Epoch [534/1000], Training Loss: 0.0188, Validation Loss: 0.0880
Epoch [535/1000], Training Loss: 0.0188, Validation Loss: 0.0880
Epoch [536/1000], Training Loss: 0.0189, Validation Loss: 0.0880
Epoch [537/1000], Training Loss: 0.0188, Validation Loss: 0.0880
Epoch [538/1000], Training Loss: 0.0188, Validation Loss: 0.0880
Epoch [539/1000], Training Loss: 0.0189, Validation Loss: 0.0881
Epoch [540/1000], Training Loss: 0.0188, Validation Loss: 0.0880
Epoch [541/1000], Training Loss: 0.0188, Validation Loss: 0.0880
Epoch [542/1000], Training Loss: 0.0187, Validation Loss: 0.0880
Epoch [543/1000], Training Loss: 0.0187, Validation Loss: 0.0880
Epoch [544/1000], Training Loss: 0.0186, Validation Loss: 0.0880
Epoch [545/1000], Training Loss: 0.0185, Validation Loss: 0.0880
Epoch [546/1000], Training Loss: 0.0186, Validation Loss: 0.0880
Epoch [547/1000], Training Loss: 0.0186, Validation Loss: 0.0879
Epoch [548/1000], Training Loss: 0.0186, Validation Loss: 0.0879
Epoch [549/1000], Training Loss: 0.0186, Validation Loss: 0.0879
Epoch [550/1000], Training Loss: 0.0185, Validation Loss: 0.0879
Epoch [551/1000], Training Loss: 0.0185, Validation Loss: 0.0878
Epoch [552/1000], Training Loss: 0.0185, Validation Loss: 0.0878
Epoch [553/1000], Training Loss: 0.0185, Validation Loss: 0.0878
Epoch [554/1000], Training Loss: 0.0184, Validation Loss: 0.0878
Epoch [555/1000], Training Loss: 0.0185, Validation Loss: 0.0878
Epoch [556/1000], Training Loss: 0.0184, Validation Loss: 0.0878
Epoch [557/1000], Training Loss: 0.0183, Validation Loss: 0.0877
Epoch [558/1000], Training Loss: 0.0182, Validation Loss: 0.0877
Epoch [559/1000], Training Loss: 0.0181, Validation Loss: 0.0876
Epoch [560/1000], Training Loss: 0.0181, Validation Loss: 0.0876
Epoch [561/1000], Training Loss: 0.0180, Validation Loss: 0.0876
Epoch [562/1000], Training Loss: 0.0181, Validation Loss: 0.0876
Epoch [563/1000], Training Loss: 0.0181, Validation Loss: 0.0876
Epoch [564/1000], Training Loss: 0.0181, Validation Loss: 0.0876
Epoch [565/1000], Training Loss: 0.0181, Validation Loss: 0.0876
Epoch [566/1000], Training Loss: 0.0179, Validation Loss: 0.0876
Epoch [567/1000], Training Loss: 0.0180, Validation Loss: 0.0876
Epoch [568/1000], Training Loss: 0.0179, Validation Loss: 0.0876
Epoch [569/1000], Training Loss: 0.0178, Validation Loss: 0.0876
Epoch [570/1000], Training Loss: 0.0179, Validation Loss: 0.0876
Epoch [571/1000], Training Loss: 0.0178, Validation Loss: 0.0876
Epoch [572/1000], Training Loss: 0.0178, Validation Loss: 0.0875
Epoch [573/1000], Training Loss: 0.0178, Validation Loss: 0.0875
Epoch [574/1000], Training Loss: 0.0178, Validation Loss: 0.0875
Epoch [575/1000], Training Loss: 0.0177, Validation Loss: 0.0875
Epoch [576/1000], Training Loss: 0.0177, Validation Loss: 0.0875
Epoch [577/1000], Training Loss: 0.0178, Validation Loss: 0.0874
Epoch [578/1000], Training Loss: 0.0177, Validation Loss: 0.0875
Epoch [579/1000], Training Loss: 0.0177, Validation Loss: 0.0875
Epoch [580/1000], Training Loss: 0.0177, Validation Loss: 0.0874
Epoch [581/1000], Training Loss: 0.0177, Validation Loss: 0.0874
Epoch [582/1000], Training Loss: 0.0177, Validation Loss: 0.0874
Epoch [583/1000], Training Loss: 0.0177, Validation Loss: 0.0874
Epoch [584/1000], Training Loss: 0.0177, Validation Loss: 0.0874
Epoch [585/1000], Training Loss: 0.0177, Validation Loss: 0.0874
Epoch [586/1000], Training Loss: 0.0177, Validation Loss: 0.0873
Epoch [587/1000], Training Loss: 0.0176, Validation Loss: 0.0874
Epoch [588/1000], Training Loss: 0.0177, Validation Loss: 0.0873
Epoch [589/1000], Training Loss: 0.0176, Validation Loss: 0.0873
Epoch [590/1000], Training Loss: 0.0177, Validation Loss: 0.0873
Epoch [591/1000], Training Loss: 0.0177, Validation Loss: 0.0873
Epoch [592/1000], Training Loss: 0.0177, Validation Loss: 0.0873
Epoch [593/1000], Training Loss: 0.0178, Validation Loss: 0.0873
Epoch [594/1000], Training Loss: 0.0177, Validation Loss: 0.0874
Epoch [595/1000], Training Loss: 0.0177, Validation Loss: 0.0873
Epoch [596/1000], Training Loss: 0.0178, Validation Loss: 0.0874
Epoch [597/1000], Training Loss: 0.0179, Validation Loss: 0.0874
Epoch [598/1000], Training Loss: 0.0179, Validation Loss: 0.0874
Epoch [599/1000], Training Loss: 0.0180, Validation Loss: 0.0874
Epoch [600/1000], Training Loss: 0.0178, Validation Loss: 0.0875
Epoch [601/1000], Training Loss: 0.0179, Validation Loss: 0.0875
Epoch [602/1000], Training Loss: 0.0179, Validation Loss: 0.0876
Epoch [603/1000], Training Loss: 0.0180, Validation Loss: 0.0876
Epoch [604/1000], Training Loss: 0.0180, Validation Loss: 0.0877
Epoch [605/1000], Training Loss: 0.0180, Validation Loss: 0.0876
Epoch [606/1000], Training Loss: 0.0180, Validation Loss: 0.0877
Epoch [607/1000], Training Loss: 0.0180, Validation Loss: 0.0876
Epoch [608/1000], Training Loss: 0.0177, Validation Loss: 0.0876
Epoch [609/1000], Training Loss: 0.0173, Validation Loss: 0.0875
Epoch [610/1000], Training Loss: 0.0172, Validation Loss: 0.0874
Epoch [611/1000], Training Loss: 0.0172, Validation Loss: 0.0873
Epoch [612/1000], Training Loss: 0.0171, Validation Loss: 0.0873
Epoch [613/1000], Training Loss: 0.0171, Validation Loss: 0.0873
Epoch [614/1000], Training Loss: 0.0170, Validation Loss: 0.0872
Epoch [615/1000], Training Loss: 0.0169, Validation Loss: 0.0871
Epoch [616/1000], Training Loss: 0.0170, Validation Loss: 0.0871
Epoch [617/1000], Training Loss: 0.0169, Validation Loss: 0.0871
Epoch [618/1000], Training Loss: 0.0171, Validation Loss: 0.0870
Epoch [619/1000], Training Loss: 0.0171, Validation Loss: 0.0870
Epoch [620/1000], Training Loss: 0.0171, Validation Loss: 0.0870
Epoch [621/1000], Training Loss: 0.0171, Validation Loss: 0.0869
Epoch [622/1000], Training Loss: 0.0172, Validation Loss: 0.0870
Epoch [623/1000], Training Loss: 0.0171, Validation Loss: 0.0869
Epoch [624/1000], Training Loss: 0.0172, Validation Loss: 0.0869
Epoch [625/1000], Training Loss: 0.0171, Validation Loss: 0.0869
Epoch [626/1000], Training Loss: 0.0172, Validation Loss: 0.0869
Epoch [627/1000], Training Loss: 0.0171, Validation Loss: 0.0868
Epoch [628/1000], Training Loss: 0.0172, Validation Loss: 0.0868
Epoch [629/1000], Training Loss: 0.0172, Validation Loss: 0.0868
Epoch [630/1000], Training Loss: 0.0171, Validation Loss: 0.0868
Epoch [631/1000], Training Loss: 0.0171, Validation Loss: 0.0867
Epoch [632/1000], Training Loss: 0.0171, Validation Loss: 0.0868
Epoch [633/1000], Training Loss: 0.0171, Validation Loss: 0.0867
Epoch [634/1000], Training Loss: 0.0171, Validation Loss: 0.0867
Epoch [635/1000], Training Loss: 0.0170, Validation Loss: 0.0866
Epoch [636/1000], Training Loss: 0.0170, Validation Loss: 0.0866
Epoch [637/1000], Training Loss: 0.0170, Validation Loss: 0.0867
Epoch [638/1000], Training Loss: 0.0170, Validation Loss: 0.0866
Epoch [639/1000], Training Loss: 0.0170, Validation Loss: 0.0867
Epoch [640/1000], Training Loss: 0.0170, Validation Loss: 0.0866
Epoch [641/1000], Training Loss: 0.0170, Validation Loss: 0.0866
Epoch [642/1000], Training Loss: 0.0170, Validation Loss: 0.0866
Epoch [643/1000], Training Loss: 0.0170, Validation Loss: 0.0866
Epoch [644/1000], Training Loss: 0.0169, Validation Loss: 0.0866
Epoch [645/1000], Training Loss: 0.0170, Validation Loss: 0.0866
Epoch [646/1000], Training Loss: 0.0170, Validation Loss: 0.0865
Epoch [647/1000], Training Loss: 0.0170, Validation Loss: 0.0866
Epoch [648/1000], Training Loss: 0.0170, Validation Loss: 0.0865
Epoch [649/1000], Training Loss: 0.0171, Validation Loss: 0.0865
Epoch [650/1000], Training Loss: 0.0170, Validation Loss: 0.0865
Epoch [651/1000], Training Loss: 0.0170, Validation Loss: 0.0865
Epoch [652/1000], Training Loss: 0.0170, Validation Loss: 0.0865
Epoch [653/1000], Training Loss: 0.0171, Validation Loss: 0.0865
Epoch [654/1000], Training Loss: 0.0170, Validation Loss: 0.0865
Epoch [655/1000], Training Loss: 0.0171, Validation Loss: 0.0865
Epoch [656/1000], Training Loss: 0.0169, Validation Loss: 0.0865
Epoch [657/1000], Training Loss: 0.0170, Validation Loss: 0.0865
Epoch [658/1000], Training Loss: 0.0170, Validation Loss: 0.0865
Epoch [659/1000], Training Loss: 0.0170, Validation Loss: 0.0865
Epoch [660/1000], Training Loss: 0.0170, Validation Loss: 0.0865
Epoch [661/1000], Training Loss: 0.0170, Validation Loss: 0.0864
Epoch [662/1000], Training Loss: 0.0170, Validation Loss: 0.0865
Epoch [663/1000], Training Loss: 0.0170, Validation Loss: 0.0865
Epoch [664/1000], Training Loss: 0.0171, Validation Loss: 0.0865
Epoch [665/1000], Training Loss: 0.0170, Validation Loss: 0.0864
Epoch [666/1000], Training Loss: 0.0170, Validation Loss: 0.0864
Epoch [667/1000], Training Loss: 0.0170, Validation Loss: 0.0864
Epoch [668/1000], Training Loss: 0.0172, Validation Loss: 0.0865
Epoch [669/1000], Training Loss: 0.0172, Validation Loss: 0.0865
Epoch [670/1000], Training Loss: 0.0171, Validation Loss: 0.0864
Epoch [671/1000], Training Loss: 0.0171, Validation Loss: 0.0864
Epoch [672/1000], Training Loss: 0.0170, Validation Loss: 0.0864
Epoch [673/1000], Training Loss: 0.0170, Validation Loss: 0.0864
Epoch [674/1000], Training Loss: 0.0170, Validation Loss: 0.0863
Epoch [675/1000], Training Loss: 0.0170, Validation Loss: 0.0863
Epoch [676/1000], Training Loss: 0.0171, Validation Loss: 0.0863
Epoch [677/1000], Training Loss: 0.0171, Validation Loss: 0.0863
Epoch [678/1000], Training Loss: 0.0170, Validation Loss: 0.0862
Epoch [679/1000], Training Loss: 0.0172, Validation Loss: 0.0863
Epoch [680/1000], Training Loss: 0.0172, Validation Loss: 0.0862
Epoch [681/1000], Training Loss: 0.0171, Validation Loss: 0.0862
Epoch [682/1000], Training Loss: 0.0172, Validation Loss: 0.0862
Epoch [683/1000], Training Loss: 0.0171, Validation Loss: 0.0862
Epoch [684/1000], Training Loss: 0.0172, Validation Loss: 0.0862
Epoch [685/1000], Training Loss: 0.0174, Validation Loss: 0.0862
Epoch [686/1000], Training Loss: 0.0173, Validation Loss: 0.0862
Epoch [687/1000], Training Loss: 0.0174, Validation Loss: 0.0861
Epoch [688/1000], Training Loss: 0.0174, Validation Loss: 0.0862
Epoch [689/1000], Training Loss: 0.0173, Validation Loss: 0.0861
Epoch [690/1000], Training Loss: 0.0175, Validation Loss: 0.0862
Epoch [691/1000], Training Loss: 0.0174, Validation Loss: 0.0862
Epoch [692/1000], Training Loss: 0.0174, Validation Loss: 0.0861
Epoch [693/1000], Training Loss: 0.0173, Validation Loss: 0.0861
Epoch [694/1000], Training Loss: 0.0173, Validation Loss: 0.0861
Epoch [695/1000], Training Loss: 0.0174, Validation Loss: 0.0861
Epoch [696/1000], Training Loss: 0.0173, Validation Loss: 0.0861
Epoch [697/1000], Training Loss: 0.0174, Validation Loss: 0.0862
Epoch [698/1000], Training Loss: 0.0173, Validation Loss: 0.0861
Epoch [699/1000], Training Loss: 0.0174, Validation Loss: 0.0861
Epoch [700/1000], Training Loss: 0.0175, Validation Loss: 0.0862
Epoch [701/1000], Training Loss: 0.0173, Validation Loss: 0.0862
Epoch [702/1000], Training Loss: 0.0174, Validation Loss: 0.0862
Epoch [703/1000], Training Loss: 0.0175, Validation Loss: 0.0862
Epoch [704/1000], Training Loss: 0.0175, Validation Loss: 0.0862
Epoch [705/1000], Training Loss: 0.0175, Validation Loss: 0.0862
Epoch [706/1000], Training Loss: 0.0174, Validation Loss: 0.0861
Epoch [707/1000], Training Loss: 0.0174, Validation Loss: 0.0861
Epoch [708/1000], Training Loss: 0.0175, Validation Loss: 0.0862
Epoch [709/1000], Training Loss: 0.0175, Validation Loss: 0.0861
Epoch [710/1000], Training Loss: 0.0175, Validation Loss: 0.0861
Epoch [711/1000], Training Loss: 0.0176, Validation Loss: 0.0862
Epoch [712/1000], Training Loss: 0.0176, Validation Loss: 0.0862
Epoch [713/1000], Training Loss: 0.0176, Validation Loss: 0.0862
Epoch [714/1000], Training Loss: 0.0176, Validation Loss: 0.0862
Epoch [715/1000], Training Loss: 0.0176, Validation Loss: 0.0862
Epoch [716/1000], Training Loss: 0.0176, Validation Loss: 0.0862
Epoch [717/1000], Training Loss: 0.0175, Validation Loss: 0.0862
Epoch [718/1000], Training Loss: 0.0176, Validation Loss: 0.0861
Epoch [719/1000], Training Loss: 0.0176, Validation Loss: 0.0861
Epoch [720/1000], Training Loss: 0.0177, Validation Loss: 0.0861
Epoch [721/1000], Training Loss: 0.0177, Validation Loss: 0.0860
Epoch [722/1000], Training Loss: 0.0176, Validation Loss: 0.0859
Epoch [723/1000], Training Loss: 0.0176, Validation Loss: 0.0859
Epoch [724/1000], Training Loss: 0.0176, Validation Loss: 0.0859
Epoch [725/1000], Training Loss: 0.0176, Validation Loss: 0.0858
Epoch [726/1000], Training Loss: 0.0176, Validation Loss: 0.0857
Epoch [727/1000], Training Loss: 0.0176, Validation Loss: 0.0857
Epoch [728/1000], Training Loss: 0.0176, Validation Loss: 0.0857
Epoch [729/1000], Training Loss: 0.0175, Validation Loss: 0.0856
Epoch [730/1000], Training Loss: 0.0176, Validation Loss: 0.0856
Epoch [731/1000], Training Loss: 0.0175, Validation Loss: 0.0856
Epoch [732/1000], Training Loss: 0.0175, Validation Loss: 0.0856
Epoch [733/1000], Training Loss: 0.0175, Validation Loss: 0.0856
Epoch [734/1000], Training Loss: 0.0176, Validation Loss: 0.0856
Epoch [735/1000], Training Loss: 0.0175, Validation Loss: 0.0856
Epoch [736/1000], Training Loss: 0.0175, Validation Loss: 0.0856
Epoch [737/1000], Training Loss: 0.0175, Validation Loss: 0.0855
Epoch [738/1000], Training Loss: 0.0176, Validation Loss: 0.0856
Epoch [739/1000], Training Loss: 0.0175, Validation Loss: 0.0856
Epoch [740/1000], Training Loss: 0.0175, Validation Loss: 0.0855
Epoch [741/1000], Training Loss: 0.0175, Validation Loss: 0.0855
Epoch [742/1000], Training Loss: 0.0176, Validation Loss: 0.0856
Epoch [743/1000], Training Loss: 0.0176, Validation Loss: 0.0856
Epoch [744/1000], Training Loss: 0.0175, Validation Loss: 0.0856
Epoch [745/1000], Training Loss: 0.0175, Validation Loss: 0.0856
Epoch [746/1000], Training Loss: 0.0176, Validation Loss: 0.0856
Epoch [747/1000], Training Loss: 0.0175, Validation Loss: 0.0856
Epoch [748/1000], Training Loss: 0.0175, Validation Loss: 0.0856
Epoch [749/1000], Training Loss: 0.0175, Validation Loss: 0.0856
Epoch [750/1000], Training Loss: 0.0176, Validation Loss: 0.0856
Epoch [751/1000], Training Loss: 0.0176, Validation Loss: 0.0856
Epoch [752/1000], Training Loss: 0.0175, Validation Loss: 0.0856
Epoch [753/1000], Training Loss: 0.0175, Validation Loss: 0.0856
Epoch [754/1000], Training Loss: 0.0176, Validation Loss: 0.0856
Epoch [755/1000], Training Loss: 0.0175, Validation Loss: 0.0856
Epoch [756/1000], Training Loss: 0.0175, Validation Loss: 0.0856
Epoch [757/1000], Training Loss: 0.0176, Validation Loss: 0.0856
Epoch [758/1000], Training Loss: 0.0176, Validation Loss: 0.0856
Epoch [759/1000], Training Loss: 0.0176, Validation Loss: 0.0857
Epoch [760/1000], Training Loss: 0.0175, Validation Loss: 0.0856
Epoch [761/1000], Training Loss: 0.0176, Validation Loss: 0.0857
Epoch [762/1000], Training Loss: 0.0176, Validation Loss: 0.0856
Epoch [763/1000], Training Loss: 0.0176, Validation Loss: 0.0856
Epoch [764/1000], Training Loss: 0.0176, Validation Loss: 0.0857
Epoch [765/1000], Training Loss: 0.0176, Validation Loss: 0.0857
Epoch [766/1000], Training Loss: 0.0176, Validation Loss: 0.0857
Epoch [767/1000], Training Loss: 0.0176, Validation Loss: 0.0857
Epoch [768/1000], Training Loss: 0.0176, Validation Loss: 0.0857
Epoch [769/1000], Training Loss: 0.0175, Validation Loss: 0.0858
Epoch [770/1000], Training Loss: 0.0176, Validation Loss: 0.0858
Epoch [771/1000], Training Loss: 0.0176, Validation Loss: 0.0858
Epoch [772/1000], Training Loss: 0.0177, Validation Loss: 0.0859
Epoch [773/1000], Training Loss: 0.0176, Validation Loss: 0.0859
Epoch [774/1000], Training Loss: 0.0177, Validation Loss: 0.0859
Epoch [775/1000], Training Loss: 0.0177, Validation Loss: 0.0859
Epoch [776/1000], Training Loss: 0.0177, Validation Loss: 0.0860
Epoch [777/1000], Training Loss: 0.0176, Validation Loss: 0.0860
Epoch [778/1000], Training Loss: 0.0177, Validation Loss: 0.0860
Epoch [779/1000], Training Loss: 0.0177, Validation Loss: 0.0860
Epoch [780/1000], Training Loss: 0.0177, Validation Loss: 0.0861
Epoch [781/1000], Training Loss: 0.0177, Validation Loss: 0.0861
Epoch [782/1000], Training Loss: 0.0178, Validation Loss: 0.0862
Epoch [783/1000], Training Loss: 0.0178, Validation Loss: 0.0862
Epoch [784/1000], Training Loss: 0.0178, Validation Loss: 0.0862
Epoch [785/1000], Training Loss: 0.0178, Validation Loss: 0.0863
Epoch [786/1000], Training Loss: 0.0177, Validation Loss: 0.0863
Epoch [787/1000], Training Loss: 0.0177, Validation Loss: 0.0863
Epoch [788/1000], Training Loss: 0.0177, Validation Loss: 0.0863
Epoch [789/1000], Training Loss: 0.0178, Validation Loss: 0.0864
Epoch [790/1000], Training Loss: 0.0177, Validation Loss: 0.0863
Epoch [791/1000], Training Loss: 0.0178, Validation Loss: 0.0864
Epoch [792/1000], Training Loss: 0.0178, Validation Loss: 0.0864
Epoch [793/1000], Training Loss: 0.0178, Validation Loss: 0.0864
Epoch [794/1000], Training Loss: 0.0178, Validation Loss: 0.0864
Epoch [795/1000], Training Loss: 0.0179, Validation Loss: 0.0865
Epoch [796/1000], Training Loss: 0.0178, Validation Loss: 0.0865
Epoch [797/1000], Training Loss: 0.0178, Validation Loss: 0.0865
Epoch [798/1000], Training Loss: 0.0179, Validation Loss: 0.0865
Epoch [799/1000], Training Loss: 0.0179, Validation Loss: 0.0865
Epoch [800/1000], Training Loss: 0.0180, Validation Loss: 0.0865
Epoch [801/1000], Training Loss: 0.0179, Validation Loss: 0.0865
Epoch [802/1000], Training Loss: 0.0179, Validation Loss: 0.0866
Epoch [803/1000], Training Loss: 0.0178, Validation Loss: 0.0866
Epoch [804/1000], Training Loss: 0.0179, Validation Loss: 0.0866
Epoch [805/1000], Training Loss: 0.0179, Validation Loss: 0.0866
Epoch [806/1000], Training Loss: 0.0179, Validation Loss: 0.0866
Epoch [807/1000], Training Loss: 0.0179, Validation Loss: 0.0866
Epoch [808/1000], Training Loss: 0.0178, Validation Loss: 0.0866
Epoch [809/1000], Training Loss: 0.0179, Validation Loss: 0.0866
Epoch [810/1000], Training Loss: 0.0178, Validation Loss: 0.0866
Epoch [811/1000], Training Loss: 0.0179, Validation Loss: 0.0867
Epoch [812/1000], Training Loss: 0.0178, Validation Loss: 0.0867
Epoch [813/1000], Training Loss: 0.0179, Validation Loss: 0.0867
Epoch [814/1000], Training Loss: 0.0179, Validation Loss: 0.0867
Epoch [815/1000], Training Loss: 0.0178, Validation Loss: 0.0867
Epoch [816/1000], Training Loss: 0.0179, Validation Loss: 0.0868
Epoch [817/1000], Training Loss: 0.0179, Validation Loss: 0.0868
Epoch [818/1000], Training Loss: 0.0178, Validation Loss: 0.0868
Epoch [819/1000], Training Loss: 0.0178, Validation Loss: 0.0867
Epoch [820/1000], Training Loss: 0.0179, Validation Loss: 0.0868
Epoch [821/1000], Training Loss: 0.0179, Validation Loss: 0.0868
Epoch [822/1000], Training Loss: 0.0179, Validation Loss: 0.0868
Epoch [823/1000], Training Loss: 0.0178, Validation Loss: 0.0868
Epoch [824/1000], Training Loss: 0.0179, Validation Loss: 0.0868
Epoch [825/1000], Training Loss: 0.0179, Validation Loss: 0.0868
Epoch [826/1000], Training Loss: 0.0178, Validation Loss: 0.0868
Epoch [827/1000], Training Loss: 0.0178, Validation Loss: 0.0868
Epoch [828/1000], Training Loss: 0.0178, Validation Loss: 0.0869
Epoch [829/1000], Training Loss: 0.0178, Validation Loss: 0.0869
Epoch [830/1000], Training Loss: 0.0178, Validation Loss: 0.0869
Epoch [831/1000], Training Loss: 0.0178, Validation Loss: 0.0869
Epoch [832/1000], Training Loss: 0.0178, Validation Loss: 0.0869
Epoch [833/1000], Training Loss: 0.0177, Validation Loss: 0.0869
Epoch [834/1000], Training Loss: 0.0177, Validation Loss: 0.0869
Epoch [835/1000], Training Loss: 0.0177, Validation Loss: 0.0869
Epoch [836/1000], Training Loss: 0.0176, Validation Loss: 0.0869
Epoch [837/1000], Training Loss: 0.0177, Validation Loss: 0.0869
Epoch [838/1000], Training Loss: 0.0176, Validation Loss: 0.0869
Epoch [839/1000], Training Loss: 0.0176, Validation Loss: 0.0870
Epoch [840/1000], Training Loss: 0.0176, Validation Loss: 0.0870
Epoch [841/1000], Training Loss: 0.0176, Validation Loss: 0.0870
Epoch [842/1000], Training Loss: 0.0175, Validation Loss: 0.0870
Epoch [843/1000], Training Loss: 0.0176, Validation Loss: 0.0870
Epoch [844/1000], Training Loss: 0.0176, Validation Loss: 0.0871
Epoch [845/1000], Training Loss: 0.0176, Validation Loss: 0.0871
Epoch [846/1000], Training Loss: 0.0176, Validation Loss: 0.0871
Epoch [847/1000], Training Loss: 0.0176, Validation Loss: 0.0871
Epoch [848/1000], Training Loss: 0.0175, Validation Loss: 0.0871
Epoch [849/1000], Training Loss: 0.0176, Validation Loss: 0.0871
Epoch [850/1000], Training Loss: 0.0175, Validation Loss: 0.0871
Epoch [851/1000], Training Loss: 0.0176, Validation Loss: 0.0871
Epoch [852/1000], Training Loss: 0.0176, Validation Loss: 0.0872
Epoch [853/1000], Training Loss: 0.0175, Validation Loss: 0.0872
Epoch [854/1000], Training Loss: 0.0175, Validation Loss: 0.0872
Epoch [855/1000], Training Loss: 0.0175, Validation Loss: 0.0872
Epoch [856/1000], Training Loss: 0.0174, Validation Loss: 0.0872
Epoch [857/1000], Training Loss: 0.0174, Validation Loss: 0.0872
Epoch [858/1000], Training Loss: 0.0175, Validation Loss: 0.0873
Epoch [859/1000], Training Loss: 0.0173, Validation Loss: 0.0872
Epoch [860/1000], Training Loss: 0.0173, Validation Loss: 0.0873
Epoch [861/1000], Training Loss: 0.0173, Validation Loss: 0.0873
Epoch [862/1000], Training Loss: 0.0172, Validation Loss: 0.0873
Epoch [863/1000], Training Loss: 0.0172, Validation Loss: 0.0872
Epoch [864/1000], Training Loss: 0.0172, Validation Loss: 0.0873
Epoch [865/1000], Training Loss: 0.0172, Validation Loss: 0.0873
Epoch [866/1000], Training Loss: 0.0173, Validation Loss: 0.0873
Epoch [867/1000], Training Loss: 0.0172, Validation Loss: 0.0872
Epoch [868/1000], Training Loss: 0.0173, Validation Loss: 0.0873
Epoch [869/1000], Training Loss: 0.0172, Validation Loss: 0.0873
Epoch [870/1000], Training Loss: 0.0172, Validation Loss: 0.0872
Epoch [871/1000], Training Loss: 0.0172, Validation Loss: 0.0873
Epoch [872/1000], Training Loss: 0.0170, Validation Loss: 0.0872
Epoch [873/1000], Training Loss: 0.0171, Validation Loss: 0.0873
Epoch [874/1000], Training Loss: 0.0171, Validation Loss: 0.0873
Epoch [875/1000], Training Loss: 0.0171, Validation Loss: 0.0873
Epoch [876/1000], Training Loss: 0.0171, Validation Loss: 0.0873
Epoch [877/1000], Training Loss: 0.0170, Validation Loss: 0.0873
Epoch [878/1000], Training Loss: 0.0171, Validation Loss: 0.0873
Epoch [879/1000], Training Loss: 0.0170, Validation Loss: 0.0873
Epoch [880/1000], Training Loss: 0.0170, Validation Loss: 0.0873
Epoch [881/1000], Training Loss: 0.0170, Validation Loss: 0.0873
Epoch [882/1000], Training Loss: 0.0170, Validation Loss: 0.0873
Epoch [883/1000], Training Loss: 0.0170, Validation Loss: 0.0874
Epoch [884/1000], Training Loss: 0.0170, Validation Loss: 0.0873
Epoch [885/1000], Training Loss: 0.0170, Validation Loss: 0.0873
Epoch [886/1000], Training Loss: 0.0171, Validation Loss: 0.0874
Epoch [887/1000], Training Loss: 0.0171, Validation Loss: 0.0874
Epoch [888/1000], Training Loss: 0.0170, Validation Loss: 0.0873
Epoch [889/1000], Training Loss: 0.0170, Validation Loss: 0.0873
Epoch [890/1000], Training Loss: 0.0170, Validation Loss: 0.0874
Epoch [891/1000], Training Loss: 0.0170, Validation Loss: 0.0874
Epoch [892/1000], Training Loss: 0.0170, Validation Loss: 0.0874
Epoch [893/1000], Training Loss: 0.0170, Validation Loss: 0.0874
Epoch [894/1000], Training Loss: 0.0170, Validation Loss: 0.0874
Epoch [895/1000], Training Loss: 0.0171, Validation Loss: 0.0874
Epoch [896/1000], Training Loss: 0.0170, Validation Loss: 0.0874
Epoch [897/1000], Training Loss: 0.0170, Validation Loss: 0.0874
Epoch [898/1000], Training Loss: 0.0170, Validation Loss: 0.0875
Epoch [899/1000], Training Loss: 0.0170, Validation Loss: 0.0875
Epoch [900/1000], Training Loss: 0.0170, Validation Loss: 0.0875
Epoch [901/1000], Training Loss: 0.0170, Validation Loss: 0.0875
Epoch [902/1000], Training Loss: 0.0171, Validation Loss: 0.0875
Epoch [903/1000], Training Loss: 0.0171, Validation Loss: 0.0875
Epoch [904/1000], Training Loss: 0.0170, Validation Loss: 0.0875
Epoch [905/1000], Training Loss: 0.0170, Validation Loss: 0.0875
Epoch [906/1000], Training Loss: 0.0171, Validation Loss: 0.0875
Epoch [907/1000], Training Loss: 0.0171, Validation Loss: 0.0875
Epoch [908/1000], Training Loss: 0.0171, Validation Loss: 0.0875
Epoch [909/1000], Training Loss: 0.0170, Validation Loss: 0.0875
Epoch [910/1000], Training Loss: 0.0171, Validation Loss: 0.0875
Epoch [911/1000], Training Loss: 0.0170, Validation Loss: 0.0876
Epoch [912/1000], Training Loss: 0.0170, Validation Loss: 0.0876
Epoch [913/1000], Training Loss: 0.0170, Validation Loss: 0.0876
Epoch [914/1000], Training Loss: 0.0169, Validation Loss: 0.0876
Epoch [915/1000], Training Loss: 0.0170, Validation Loss: 0.0876
Epoch [916/1000], Training Loss: 0.0169, Validation Loss: 0.0876
Epoch [917/1000], Training Loss: 0.0169, Validation Loss: 0.0876
Epoch [918/1000], Training Loss: 0.0169, Validation Loss: 0.0876
Epoch [919/1000], Training Loss: 0.0169, Validation Loss: 0.0876
Epoch [920/1000], Training Loss: 0.0169, Validation Loss: 0.0876
Epoch [921/1000], Training Loss: 0.0169, Validation Loss: 0.0876
Epoch [922/1000], Training Loss: 0.0169, Validation Loss: 0.0876
Epoch [923/1000], Training Loss: 0.0169, Validation Loss: 0.0876
Epoch [924/1000], Training Loss: 0.0169, Validation Loss: 0.0876
Epoch [925/1000], Training Loss: 0.0169, Validation Loss: 0.0876
Epoch [926/1000], Training Loss: 0.0169, Validation Loss: 0.0876
Epoch [927/1000], Training Loss: 0.0168, Validation Loss: 0.0876
Epoch [928/1000], Training Loss: 0.0168, Validation Loss: 0.0876
Epoch [929/1000], Training Loss: 0.0169, Validation Loss: 0.0877
Epoch [930/1000], Training Loss: 0.0169, Validation Loss: 0.0876
Epoch [931/1000], Training Loss: 0.0169, Validation Loss: 0.0877
Epoch [932/1000], Training Loss: 0.0169, Validation Loss: 0.0877
Epoch [933/1000], Training Loss: 0.0170, Validation Loss: 0.0877
Epoch [934/1000], Training Loss: 0.0169, Validation Loss: 0.0877
Epoch [935/1000], Training Loss: 0.0169, Validation Loss: 0.0877
Epoch [936/1000], Training Loss: 0.0168, Validation Loss: 0.0877
Epoch [937/1000], Training Loss: 0.0168, Validation Loss: 0.0877
Epoch [938/1000], Training Loss: 0.0169, Validation Loss: 0.0877
Epoch [939/1000], Training Loss: 0.0170, Validation Loss: 0.0878
Epoch [940/1000], Training Loss: 0.0169, Validation Loss: 0.0877
Epoch [941/1000], Training Loss: 0.0169, Validation Loss: 0.0877
Epoch [942/1000], Training Loss: 0.0169, Validation Loss: 0.0877
Epoch [943/1000], Training Loss: 0.0169, Validation Loss: 0.0877
Epoch [944/1000], Training Loss: 0.0169, Validation Loss: 0.0877
Epoch [945/1000], Training Loss: 0.0169, Validation Loss: 0.0878
Epoch [946/1000], Training Loss: 0.0169, Validation Loss: 0.0877
Epoch [947/1000], Training Loss: 0.0169, Validation Loss: 0.0877
Epoch [948/1000], Training Loss: 0.0168, Validation Loss: 0.0878
Epoch [949/1000], Training Loss: 0.0168, Validation Loss: 0.0877
Epoch [950/1000], Training Loss: 0.0169, Validation Loss: 0.0877
Epoch [951/1000], Training Loss: 0.0169, Validation Loss: 0.0878
Epoch [952/1000], Training Loss: 0.0169, Validation Loss: 0.0878
Epoch [953/1000], Training Loss: 0.0169, Validation Loss: 0.0878
Epoch [954/1000], Training Loss: 0.0169, Validation Loss: 0.0878
Epoch [955/1000], Training Loss: 0.0168, Validation Loss: 0.0878
Epoch [956/1000], Training Loss: 0.0169, Validation Loss: 0.0878
Epoch [957/1000], Training Loss: 0.0168, Validation Loss: 0.0878
Epoch [958/1000], Training Loss: 0.0169, Validation Loss: 0.0878
Epoch [959/1000], Training Loss: 0.0168, Validation Loss: 0.0879
Epoch [960/1000], Training Loss: 0.0168, Validation Loss: 0.0878
Epoch [961/1000], Training Loss: 0.0168, Validation Loss: 0.0879
Epoch [962/1000], Training Loss: 0.0168, Validation Loss: 0.0879
Epoch [963/1000], Training Loss: 0.0168, Validation Loss: 0.0879
Epoch [964/1000], Training Loss: 0.0167, Validation Loss: 0.0878
Epoch [965/1000], Training Loss: 0.0168, Validation Loss: 0.0879
Epoch [966/1000], Training Loss: 0.0168, Validation Loss: 0.0878
Epoch [967/1000], Training Loss: 0.0167, Validation Loss: 0.0878
Epoch [968/1000], Training Loss: 0.0168, Validation Loss: 0.0879
Epoch [969/1000], Training Loss: 0.0168, Validation Loss: 0.0878
Epoch [970/1000], Training Loss: 0.0168, Validation Loss: 0.0878
Epoch [971/1000], Training Loss: 0.0168, Validation Loss: 0.0878
Epoch [972/1000], Training Loss: 0.0167, Validation Loss: 0.0878
Epoch [973/1000], Training Loss: 0.0168, Validation Loss: 0.0878
Epoch [974/1000], Training Loss: 0.0167, Validation Loss: 0.0878
Epoch [975/1000], Training Loss: 0.0167, Validation Loss: 0.0879
Epoch [976/1000], Training Loss: 0.0168, Validation Loss: 0.0878
Epoch [977/1000], Training Loss: 0.0168, Validation Loss: 0.0878
Epoch [978/1000], Training Loss: 0.0168, Validation Loss: 0.0878
Epoch [979/1000], Training Loss: 0.0168, Validation Loss: 0.0878
Epoch [980/1000], Training Loss: 0.0168, Validation Loss: 0.0878
Epoch [981/1000], Training Loss: 0.0169, Validation Loss: 0.0878
Epoch [982/1000], Training Loss: 0.0168, Validation Loss: 0.0878
Epoch [983/1000], Training Loss: 0.0168, Validation Loss: 0.0878
Epoch [984/1000], Training Loss: 0.0169, Validation Loss: 0.0878
Epoch [985/1000], Training Loss: 0.0168, Validation Loss: 0.0878
Epoch [986/1000], Training Loss: 0.0168, Validation Loss: 0.0878
Epoch [987/1000], Training Loss: 0.0168, Validation Loss: 0.0878
Epoch [988/1000], Training Loss: 0.0168, Validation Loss: 0.0878
Epoch [989/1000], Training Loss: 0.0168, Validation Loss: 0.0878
Epoch [990/1000], Training Loss: 0.0168, Validation Loss: 0.0878
Epoch [991/1000], Training Loss: 0.0169, Validation Loss: 0.0878
Epoch [992/1000], Training Loss: 0.0169, Validation Loss: 0.0878
Epoch [993/1000], Training Loss: 0.0169, Validation Loss: 0.0879
Epoch [994/1000], Training Loss: 0.0169, Validation Loss: 0.0879
Epoch [995/1000], Training Loss: 0.0169, Validation Loss: 0.0879
Epoch [996/1000], Training Loss: 0.0170, Validation Loss: 0.0880
Epoch [997/1000], Training Loss: 0.0170, Validation Loss: 0.0880
Epoch [998/1000], Training Loss: 0.0169, Validation Loss: 0.0880
Epoch [999/1000], Training Loss: 0.0170, Validation Loss: 0.0880
Epoch [1000/1000], Training Loss: 0.0169, Validation Loss: 0.0879
